---
title: "Acoustic Data Analysis Group Project"
output: html_document
---

Import Libraries

```{r}
#install.packages("readr")
#install.packages("tuneR")
#install.packages("seewave")
#install.packages('soundgen')
library(readr)
library(tuneR)
library(seewave)
library(soundgen)
```

The Dataset:
Sound files used for this project were downloaded from Dryad. They were recorded male zebrafinch songs that were used as playback stimuli in the following study:

D'Amelio, Pietro B. et al. (2018), Data from: Individual recognition of opposite sex vocalizations in the zebra finch, Dryad, Dataset, https://doi.org/10.5061/dryad.4g8b7



```{r}
aud1 <- "zebra finch songs/f_mal11_song_6.wav"
dat1 <- readWave(aud1)
str(dat1)

aud2 <- "zebra finch songs/f_mal1_song_1.wav"
dat2 <- readWave(aud2)
str(dat2)

aud3 <- "zebra finch songs/f_mal5_song_1.wav"
dat3 <- readWave(aud3)
str(dat3)

aud4 <- "zebra finch songs/m_mal2_song_1.wav"
dat4 <- readWave(aud4)
str(dat4)

aud5 <- "zebra finch songs/m_mal9_song_4.wav"
dat5 <- readWave(aud5)
str(dat5)

```

```{r}
par(mfrow=c(3,2))
sig1 <- dat1@left
sig1 = sig1 - mean(sig1)
# plot waveform
plot(sig1, type = 'l', xlab = 'Samples', ylab = 'Amplitude')

sig2 <- dat2@left
sig2 = sig2 - mean(sig2)
# plot waveform
plot(sig2, type = 'l', xlab = 'Samples', ylab = 'Amplitude')

sig3 <- dat3@left
sig3 = sig3 - mean(sig3)
# plot waveform
plot(sig3, type = 'l', xlab = 'Samples', ylab = 'Amplitude')

sig4 <- dat4@left
sig4 = sig4 - mean(sig4)
# plot waveform
plot(sig4, type = 'l', xlab = 'Samples', ylab = 'Amplitude')

sig5 <- dat5@left
sig5 = sig5 - mean(sig2)
# plot waveform
plot(sig5, type = 'l', xlab = 'Samples', ylab = 'Amplitude')

```

```{r}
par(mfcol=c(3,2))

data(sig1)
spectro(sig1,f=44100,
palette=temp.colors,
collevels=seq(-100,0,1))

data(sig2)
spectro(sig2,f=44100,
palette=temp.colors,
collevels=seq(-100,0,1))

data(sig3)
spectro(sig3,f=44100,
palette=temp.colors,
collevels=seq(-100,0,1))

data(sig4)
spectro(sig4,f=44100,
palette=temp.colors,
collevels=seq(-100,0,1))

data(sig5)
spectro(sig5,f=44100,
palette=temp.colors,
collevels=seq(-100,0,1))


```



Luke's section:

Use readWave from the tuneR library to read in our wav files:

```{r}
LL=readWave("zebra finch songs/m_mal2_song_1.wav")
play(LL)
```

Visualizing Temporal Characteristics of Sound 

- When analyzing animal vocalizations, or other sounds, temporal characteristics are often of interest as different calls typically differ in temporal structure.
- The soundGen package has many functions to tease out the temporal patterns present in vocalizations.

- First we will use the segment() function to look for patterns in our zebrafinch vocalizations. 
- This function allows us to identify bursts of vocal activity, as well as identify continuous syllables.
- The key parameters to set here relate to noise, as our signal must be teased apart from any background noise to be properly processed. Sounds recorded in the field can have a great deal of environmental noise due to abiotic and biotic sources, so tweaking parameters related to noise will be crucial for allowing the algorithm to differentiate between signal and noise. Sounds recorded in the lab will have less noise, but may still have unwanted noise due to breathing sounds or movement of the focal animal.
- segment() assumes that the sound of interest to us will be the loudest sound in our recording, and then the user can set the proportion of the soundfile they expect to contain noise (propNoise), as well as the signal-to-noise ratio (SNR) that must be exceeded in order for the sound to be identified as our signal.
-Users need to tune these to find acceptable balance between false-positives and false-negatives when detecting signals.
- There are also a few methods you can use, but because we have already been talking about spectrograms, I have opted for the spectrogram method (method='spec'). 
- Setting the shortest acceptable syllable length (in ms) will also be important. this sets a lower bound on what can be categorized as a syllable. Here we set it to 5ms (shortestSyl = 5).




Plot with SNR= 2

```{r}
seg_LL_2=segment(LL, 
               SNR = 2, 
               plot = TRUE, 
               method='spec', 
               propNoise=0.386, 
               shortestSyl = 5, 
               showLegend=TRUE )
```

- Here, we see red stars denoting notes whihc have been classified as syllables, blue lines denoting the durations of these continuous, separate syllables, and a green line envelope denoting bursts of sound activity. Not all
- Not all peaks that may be of interest to us are flagged as significantly syllabic (e.g. ~200ms-300ms). We can tweak the parameters and see whether this changes things.


Plot with SNR = 1

```{r}
seg_LL_1=segment(LL, 
               SNR = 1, 
               plot = TRUE, 
               method='spec', 
               propNoise=0.386, 
               shortestSyl = 5, 
               showLegend=TRUE )
```

- More peaks are recognized as syllables. The best choice of these parameters will depend on the question of interest and knowledge regarding the study species. 

  


Extracting Temporal values

- As well as visualizing the burst and syllable structure, you can extract temporal values. This could be useful in comparing/contrasting different vocalization types. For example, in many acoustically-signalling animals, call rate is important in female choice. Thus, you might expect syllable length and inter-syllable pauses to differe between vocalizations shaped by mate choice, and those adapted for other purposes.
-After performing segmentation analysis, we can extract temporal summary statistics.

```{r}
#mean and median length of syllables
mn_syl=round(mean(seg_LL_1$syllables$sylLen, na.rm = TRUE), digits=2)
md_syl=round(median(seg_LL_1$syllables$sylLen, na.rm = TRUE), digits=2)
paste("Mean syllable length is ", mn_syl, "ms, and the median syllable length is", md_syl, "ms.")

#median pause length (ms)
mn_pause=round(mean(seg_LL_1$syllables$pauseLen, na.rm = TRUE), digits=2)
md_pause=round(median(seg_LL_1$syllables$pauseLen, na.rm = TRUE), digits=2)
paste("Mean inter-syllable pause length is ", mn_pause, "ms, and the median syllable length is", md_pause, "ms.")

```



Visualizing Temporal Autocorrelation

- We can also plot a self-similarity matrix that visualizes correlations in acoustic properties between different song segments by simply plotting the spectral qualities of the song against itself. In this image, warmer colours indicate higher degrees of similarity between different song segments.

```{r}
ssm=ssm(LL)
```

- There does not seem to be a lot of temporal autocorrelation.


- Below is an SSM run on an altered portion of the same vocalization, however, I have cut and pasted a phrase found early in the vocalization at an additional 3 times during the song.

```{r}
LL_repeat=readWave("zebra finch songs/m_mal2_song_1_altered.wav")
play(LL_repeat)
```

```{r}
ssm_repeat=ssm(LL_repeat)
```

- You can see that the red lines indicating strong correlations appear where this repeated phrase is located. Thus, you can see how this visualization could be useful when checking for repeated elements in a vocalization.  
