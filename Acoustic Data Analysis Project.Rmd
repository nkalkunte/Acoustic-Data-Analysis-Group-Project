---
title: "Acoustic Data Analysis Group Project"
output: html_document
---
# Acounstic Data in R
We should give a background on the wave data class. 

Import Libraries
```{r}
#install.packages("readr")
#install.packages("tuneR")
#install.packages("seewave")
#install.packages('soundgen')
#intall.package(tidyverse)
library(readr)
library(tuneR)
library(seewave)
library(soundgen)
library(tidyverse)
```

The Dataset:
Sound files used for this project were downloaded from Dryad. They were recorded male zebrafinch songs that were used as playback stimuli in the following study:

D'Amelio, Pietro B. et al. (2018), Data from: Individual recognition of opposite sex vocalizations in the zebra finch, Dryad, Dataset, https://doi.org/10.5061/dryad.4g8b7


## Importing Data Files
The tuneR function has various function that facilitate the reading in of different audio file formats. Here we use readWave function to read in .wav files. 
```{r}
#Sample 1 
aud1 <- "zebra finch songs/f_mal11_song_6.wav"
dat1 <- readWave(aud1)
#Sample 2
aud2 <- "zebra finch songs/f_mal1_song_1.wav"
dat2 <- readWave(aud2)
#Sample 3
aud3 <- "zebra finch songs/f_mal5_song_1.wav"
dat3 <- readWave(aud3)
#Sample 4
aud4 <- "zebra finch songs/m_mal2_song_1.wav"
dat4 <- readWave(aud4)
#Sample 5
aud5 <- "zebra finch songs/m_mal9_song_4.wav"
dat5 <- readWave(aud5)

#Playing and shoring Data strucutre of sound files
play(aud1)
str(dat1)
```

## Visualizing Sound Files
While there are various ways to visualize the data encompassed in a sound file, by the far the most common is plotting the amplitude. @Smruti: can you explain how this code works? what does the @left do and why do we need to subtract the mean? Also in the xlab samples or should it be time?
```{r}
sig1 <- dat1@left
# plot waveform
plot(sig1, type = 'l', xlab = 'Samples', ylab = 'Amplitude')
title('Sample 1')

par(mfrow=c(3,2))
# plot waveform
plot(sig1, type = 'l', xlab = 'Samples', ylab = 'Amplitude')
title('Sample 1')

sig2 <- dat2@left
sig2 = sig2 - mean(sig2)
# plot waveform
plot(sig2, type = 'l', xlab = 'Samples', ylab = 'Amplitude')
title('Sample 2')

sig3 <- dat3@left
sig3 = sig3 - mean(sig3)
# plot waveform
plot(sig3, type = 'l', xlab = 'Samples', ylab = 'Amplitude')
title('Sample 3')

sig4 <- dat4@left
sig4 = sig4 - mean(sig4)
# plot waveform
plot(sig4, type = 'l', xlab = 'Samples', ylab = 'Amplitude')
title('Sample 4')

sig5 <- dat5@left
sig5 = sig5 - mean(sig5)
# plot waveform
plot(sig5, type = 'l', xlab = 'Samples', ylab = 'Amplitude')
title('Sample 5')

```
Another common visualization of sound files are Spectrograms.These represent the variation of sounds frequency over time. The spectrogram below has been overlaid by an amplitude plot. The loudest amplitude in the signal shown is 0dB - in red. 
The spectro() function in the seewave package allows us to plot this spectrogram. 
spectro() requires the signal to be plotted, f = sampling frequency of the wave, palette = colour palette for amp, collevels = set of levels used to define a range of amplitudes in the spectrogram.

```{r}
par(mfrow=c(3,2))

#data(sig1)
spectro(sig1,f=44100,
palette=temp.colors,
collevels=seq(-100,0,1))
title("Sample 1")

#data(sig2)
spectro(sig2,f=44100,
palette=temp.colors,
collevels=seq(-100,0,1))
title("Sample 2")

#data(sig3)
spectro(sig3,f=44100,
palette=temp.colors,
collevels=seq(-100,0,1))
title("Sample 3")

#data(sig4)
spectro(sig4,f=44100,
palette=temp.colors,
collevels=seq(-100,0,1))
title("Sample 4")

#data(sig5)
spectro(sig5,f=44100,
palette=temp.colors,
collevels=seq(-100,0,1))
title("Sample 5")


```

## Summary Characteristics of Sound Files
Dominant frequency (DF) is a  useful characteristic of species calls. It is defined as the frequency of sound with the highest amplitude in our sample at each time point. We can easily find the DF of our samples using the dfreq function in the seewave package. 
```{r}
df1 = as_tibble(dfreq(dat1))
df2 = as_tibble(dfreq(dat2))
df3 = as_tibble(dfreq(dat3))
df4 = as_tibble(dfreq(dat4))
df5 = as_tibble(dfreq(dat5))

# Plotting Dominant Frequencies
df1$Sample = "Sample 1"
df2$Sample = "Sample 2"
df3$Sample = "Sample 3"
df1$Sample = "Sample 1"

```


Luke's section:

Use readWave from the tuneR library to read in our wav files:

```{r}
LL=readWave("zebra finch songs/m_mal2_song_1.wav")
play(LL)
```

## Visualizing Temporal Characteristics of Sound 
When analyzing animal vocalizations, or other sounds, temporal characteristics are often of interest as different calls typically differ in temporal structure.The soundGen package has many functions to tease out the temporal patterns present in vocalizations.First we will use the segment() function to look for patterns in our zebrafinch vocalizations. 
- This function allows us to identify bursts of vocal activity, as well as identify continuous syllables.
- The key parameters to set here relate to noise, as our signal must be teased apart from any background noise to be properly processed. Sounds recorded in the field can have a great deal of environmental noise due to abiotic and biotic sources, so tweaking parameters related to noise will be crucial for allowing the algorithm to differentiate between signal and noise. Sounds recorded in the lab will have less noise, but may still have unwanted noise due to breathing sounds or movement of the focal animal.
- segment() assumes that the sound of interest to us will be the loudest sound in our recording, and then the user can set the proportion of the soundfile they expect to contain noise (propNoise), as well as the signal-to-noise ratio (SNR) that must be exceeded in order for the sound to be identified as our signal.
-Users need to tune these to find acceptable balance between false-positives and false-negatives when detecting signals.
- There are also a few methods you can use, but because we have already been talking about spectrograms, I have opted for the spectrogram method (method='spec'). 
- Setting the shortest acceptable syllable length (in ms) will also be important. this sets a lower bound on what can be categorized as a syllable. Here we set it to 5ms (shortestSyl = 5).




Plot with SNR= 2

```{r}
seg_LL_2=segment(LL, 
               SNR = 2, 
               plot = TRUE, 
               method='spec', 
               propNoise=0.386, 
               shortestSyl = 5, 
               showLegend=TRUE )
```

- Here, we see red stars denoting notes whihc have been classified as syllables, blue lines denoting the durations of these continuous, separate syllables, and a green line envelope denoting bursts of sound activity. Not all
- Not all peaks that may be of interest to us are flagged as significantly syllabic (e.g. ~200ms-300ms). We can tweak the parameters and see whether this changes things.


Plot with SNR = 1

```{r}
seg_LL_1=segment(LL, 
               SNR = 1, 
               plot = TRUE, 
               method='spec', 
               propNoise=0.386, 
               shortestSyl = 5, 
               showLegend=TRUE )
```

- More peaks are recognized as syllables. The best choice of these parameters will depend on the question of interest and knowledge regarding the study species. 

  


Extracting Temporal values

- As well as visualizing the burst and syllable structure, you can extract temporal values. This could be useful in comparing/contrasting different vocalization types. For example, in many acoustically-signalling animals, call rate is important in female choice. Thus, you might expect syllable length and inter-syllable pauses to differe between vocalizations shaped by mate choice, and those adapted for other purposes.
-After performing segmentation analysis, we can extract temporal summary statistics.

```{r}
#mean and median length of syllables
mn_syl=round(mean(seg_LL_1$syllables$sylLen, na.rm = TRUE), digits=2)
md_syl=round(median(seg_LL_1$syllables$sylLen, na.rm = TRUE), digits=2)
paste("Mean syllable length is ", mn_syl, "ms, and the median syllable length is", md_syl, "ms.")

#median pause length (ms)
mn_pause=round(mean(seg_LL_1$syllables$pauseLen, na.rm = TRUE), digits=2)
md_pause=round(median(seg_LL_1$syllables$pauseLen, na.rm = TRUE), digits=2)
paste("Mean inter-syllable pause length is ", mn_pause, "ms, and the median syllable length is", md_pause, "ms.")

```



Visualizing Temporal Autocorrelation

- We can also plot a self-similarity matrix that visualizes correlations in acoustic properties between different song segments by simply plotting the spectral qualities of the song against itself. In this image, warmer colours indicate higher degrees of similarity between different song segments.

```{r}
ssm=ssm(LL)
```

- There does not seem to be a lot of temporal autocorrelation.


- Below is an SSM run on an altered portion of the same vocalization, however, I have cut and pasted a phrase found early in the vocalization at an additional 3 times during the song.

```{r}
LL_repeat=readWave("zebra finch songs/m_mal2_song_1_altered.wav")
play(LL_repeat)
```

```{r}
ssm_repeat=ssm(LL_repeat)
```

- You can see that the red lines indicating strong correlations appear where this repeated phrase is located. Thus, you can see how this visualization could be useful when checking for repeated elements in a vocalization.  
